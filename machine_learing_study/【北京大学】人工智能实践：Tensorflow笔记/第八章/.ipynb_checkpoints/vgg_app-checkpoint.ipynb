{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[215 176 148]\n",
      "  [215 176 148]\n",
      "  [215 176 148]\n",
      "  ...\n",
      "  [240 206 182]\n",
      "  [255 236 210]\n",
      "  [136 117  90]]\n",
      "\n",
      " [[215 176 148]\n",
      "  [215 176 148]\n",
      "  [215 176 148]\n",
      "  ...\n",
      "  [148 108  96]\n",
      "  [157 123 110]\n",
      "  [ 63  36  22]]\n",
      "\n",
      " [[214 175 147]\n",
      "  [214 175 147]\n",
      "  [214 175 147]\n",
      "  ...\n",
      "  [ 35  17  10]\n",
      "  [ 42  29  21]\n",
      "  [ 57  47  40]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[206 193 185]\n",
      "  [208 192 185]\n",
      "  [211 192 185]\n",
      "  ...\n",
      "  [255 253 254]\n",
      "  [229 217 215]\n",
      "  [197 183 177]]\n",
      "\n",
      " [[207 191 184]\n",
      "  [207 191 184]\n",
      "  [211 195 188]\n",
      "  ...\n",
      "  [250 255 254]\n",
      "  [178 181 179]\n",
      "  [172 173 169]]\n",
      "\n",
      " [[207 191 184]\n",
      "  [207 191 184]\n",
      "  [210 194 187]\n",
      "  ...\n",
      "  [229 234 233]\n",
      "  [197 200 198]\n",
      "  [246 247 243]]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "path=\"pic/ILSVRC2012_val_00000128.JPEG\"\n",
    "img=io.imread(path)\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#app.py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import vgg16\n",
    "import utils\n",
    "import Nclasses import labels\n",
    "\n",
    "img_path = input(\"Input the path ande image name:\")\n",
    "img_ready = utils.load_image(img_path)\n",
    "\n",
    "fig=plt.figure(u\"Top-5 预测结果\")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    images = tf.placeholder(tf.float32,[1,224,224,3])\n",
    "    vgg=vgg16.Vgg16()\n",
    "    vgg.forward(images)\n",
    "    probability=sess.run(vgg.prob,feed_dict={image:img_ready})\n",
    "    top5=np.argsort(probability[0])[-1:-6:-1]\n",
    "    printf(\"top5:\",top5)\n",
    "    value=[]\n",
    "    bar_label=[]\n",
    "    for n,i in enumerate(top5):\n",
    "        print(\"n:\",n)\n",
    "        print(\"i:\",i)\n",
    "        values.append(probability[0][i])\n",
    "        bar_label.append(labels[i])\n",
    "        print(i,\":\",labels[i],\"----\",utils.percent(probability[0][i]))\n",
    "    \n",
    "    ax=fig.add_subplot(111)\n",
    "    ax.bar(range(len(values)),values,tick_label=bar_label,width=0.5,fc='g')\n",
    "    ax.set_ylabel(u\"probabilityit\")\n",
    "    ax.set_title(u\"Top-5\")\n",
    "    for a,b in zip(range(len(values)),values):\n",
    "        ax.text(a,b+0.0005,utils.percent(b),ha='center',va='bottom',fontsize=7)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#util.py\n",
    "from skimage import io,transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from pylab import mpl \n",
    "\n",
    "mpl.rcParams['font.sans-serif']=['SimHei']\n",
    "mpl.rcParams['axes.unicode_minus']=False\n",
    "\n",
    "def load_image(path):\n",
    "    fig=plt.figure(\"Center and Resize\")\n",
    "    img=io.imread(path)\n",
    "    img=img/255.0\n",
    "    \n",
    "    ax0=fig.add_subplot(131)\n",
    "    ax0.set_xlabel(u'Original Picture')\n",
    "    ax0.imshow(img)\n",
    "    \n",
    "    short_edge=min(img.shape[:2])\n",
    "    y=(img.shape[0]-short_edge)/2\n",
    "    x=(img.shape[1]-short_edge)/2\n",
    "    crop_img=img[y:y+short_edge,x:x+short_edge]\n",
    "    \n",
    "    ax1=fig.add_subplot(132)\n",
    "    ax1.set_xlabel(u'Centre Picture')\n",
    "    ax1.imshow(crop_img)\n",
    "    \n",
    "    re_img=transform.resize(crop_img,(224,224))\n",
    "    \n",
    "    ax2=fig.add_subplot(133)\n",
    "    ax2.set_xlabel(u'Resize Picture')\n",
    "    ax2.imshow(re_img)\n",
    "    \n",
    "    img_ready=re_img.reshape((1,224,224,3))\n",
    "\n",
    "def percent(value):\n",
    "    return \"%.2f%%\"%(value*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-6f26322a0c95>, line 53)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-6f26322a0c95>\"\u001b[1;36m, line \u001b[1;32m53\u001b[0m\n\u001b[1;33m    self.fc8=self.fc_layer(self.relu7.)\u001b[0m\n\u001b[1;37m                                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#vgg16.py\n",
    "import inspect\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "VGG_MEAN=[103.939,116.779,123.68]\n",
    "\n",
    "class Vgg16():\n",
    "    def __init__(self,vgg16_path=None):\n",
    "        if vgg16_path is None:\n",
    "            vgg16_path=os.path.join(os.getcwd(),\"vgg16.npy\")\n",
    "            self.data_dict=np.load(vgg16_path,encoding=\"latin1\").item()\n",
    "    \n",
    "    def forward(self,images):\n",
    "        print(\"build model started\")\n",
    "        start_time=time.time()\n",
    "        rgb_scaled=images*255.0\n",
    "        red,green,blue=tf.split(rgb_scaled,3,3)\n",
    "        bgr=tf.concat([blue-VGG_MEAN[0],green-VGG_MEAN[1],red-VGG_MEAN[2]],3)\n",
    "        \n",
    "        self.conv1_1=self.conv_layer(bgr,\"conv1_1\")\n",
    "        self.conv1_2=self.conv_layer(self.conv1_1,\"conv1_2\")\n",
    "        self.pool1=self.max_pool_2x2(self.conv1_2,\"pool1\")\n",
    "        \n",
    "        self.conv2_1=self.conv_layer(self.pool1,\"conv2_1\")\n",
    "        self.conv2_2=self.conv_layer(self.conv2_1,\"conv2_2\")\n",
    "        self.pool2=self.max_pool_2x2(self.conv2_2,\"pool2\")\n",
    "        \n",
    "        self.conv3_1=self.conv_layer(self.pool2,\"conv3_1\")\n",
    "        self.conv3_2=self.conv_layer(self.conv3_1,\"conv3_2\")\n",
    "        self.conv3_3=self.conv_layer(self.conv3_2,\"conv3_3\")\n",
    "        self.pool3=self.max_pool_2x2(self.conv3_3,\"pool3\")\n",
    "        \n",
    "        self.conv4_1=self.conv_layer(self.pool3,\"conv4_1\")\n",
    "        self.conv4_2=self.conv_layer(self.conv4_1,\"conv4_2\")\n",
    "        self.conv4_3=self.conv_layer(self.conv4_2,\"conv4_3\")\n",
    "        self.pool4=self.max_pool_2x2(self.conv4_3,\"pool4\")\n",
    "        \n",
    "        self.conv5_1=self.conv_layer(self.pool4,\"conv5_1\")\n",
    "        self.conv5_2=self.conv_layer(self.conv5_1,\"conv5_2\")\n",
    "        self.conv5_3=self.conv_layer(self.conv5_2,\"conv5_3\")\n",
    "        self.pool5=self.max_pool_2x2(self.conv5_3,\"pool5\")\n",
    "        \n",
    "        self.fc6=self.fc_layer(self.pool5,\"fc6\")\n",
    "        self.relu6=tf.nn.relu(self.fc6)\n",
    "        \n",
    "        self.fc7=self.fc_layer(self.relu6,\"fc7\")\n",
    "        self.relu7=tf.nn.relu(self.fc7)\n",
    "        \n",
    "        self.fc8=self.fc_layer(self.relu7,\"fc8\")\n",
    "        self.prob=tf.nn.softmax(self.fc8,name=\"prob\")\n",
    "        \n",
    "        end_time=time.time()\n",
    "        print(\"time consuming: %f\"%(end_time-start_time))\n",
    "        \n",
    "    def conv_layer(self,x,name):\n",
    "        with tf.variable_scope(name):\n",
    "            w = self.get_conv_filter(name)\n",
    "            conv=tf.nn.conv2d(x,w,[1,1,1,1],padding=\"SAME\")\n",
    "            conv_biases=self.get_bias(name)\n",
    "            result=tf.nn.relu(tf.nn.bias_add(conv,conv_biases))\n",
    "            return result\n",
    "    \n",
    "    def get_conv_filter(self,name):\n",
    "        return tf.constant(self.data_dict[name][0],name=\"filter\")\n",
    "    \n",
    "    def get_bias(self,name):\n",
    "        return tf.constant(self.data_dict[name][1],name=\"biases\")\n",
    "    \n",
    "    def max_pool_2x2(self,x,name):\n",
    "        return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME',name=name)\n",
    "    \n",
    "    def fc_layer(self,x,name):\n",
    "        with tf.variable_scope(name):\n",
    "            shape=x.get_shape().as_list()\n",
    "            dim=1\n",
    "            for i in shape[1:]:\n",
    "                dim *= i\n",
    "            x=tf.reshape(x,[-1,dim])\n",
    "            w=self.get_fc_weight(name)\n",
    "            b=self.get_bias(name)\n",
    "            \n",
    "            result = tf.nn.bias_add(tf.matmul(x,w),b)\n",
    "            \n",
    "            return result\n",
    "    \n",
    "    def get_fc_weight(self,name):\n",
    "        return ft.constant(self.data_dict[name][0],name=\"weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
