# 第一部分的小作业
*  实现 sigmoid
*  实现 softmax
*  实现 softmax交叉熵
*  实现 sigmoid交叉熵

# 第二部分的小作业
*  实现 tensorflow 的训练，可是不知道为什么 要训练好久，而且一开始的精度好低


# 第三部分的小作业
*  <s>实现 numpy的二层神经网络的计算  不知道为什么，loss降不下去 划了一个弧形，竟然拐上去了！！ 一开始0.1 然后0.3 之后回到0.9 并稳定，不知为什么</s>
* 已经在 Jerrik Eph 大神的帮助下解决，原来是我的relu函数的反向传播写错了，非常感谢！
